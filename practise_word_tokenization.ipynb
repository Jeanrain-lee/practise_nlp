{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"practise_word_tokenization.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPxAF5TTVAG6p0c/Rc6d2Vv"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"7imv6O18d2jB","colab_type":"text"},"source":["# 딥러닝을 이용한 자연어 처리 입문(https://wikidocs.net/book/2155) 학습 </br> \n","˙ 자연어처리(Natural Language Processing) </br>\n",": 우리가 쓰는 말의 의미를 분석 컴퓨터가 처리할 수 있도록함 </br>\n","=> 음성 인식, 내용 요약, 번역, 감성 분석, 텍스트 분류 작업(스펨 메일 분류, 뉴스 기사 카테고리 분류), 질의 응답 시스템, 챗봇 등에서 사용됨 </br>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"cAoK9pFjh7s7","colab_type":"text"},"source":["# 텍스트 전처리(Text preprocessing) </br>\n","=> 각자 상황에 맞게 텍스트 사전 처리 </br>\n","1) 토큰화(Tokenization)\n",": corpus를 token 단위로 나누는 작업 </br>"]},{"cell_type":"code","metadata":{"id":"QjsfnDRvdGYv","colab_type":"code","colab":{}},"source":["# Word Tokenization : 토큰의 기준이 단어(단어구, 의미를 갖는 문자열도 가능)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sFRZZSPwkahW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"3ced17d7-55b2-4867-b0c6-f19e20a53781","executionInfo":{"status":"ok","timestamp":1584600872846,"user_tz":-540,"elapsed":1048,"user":{"displayName":"이진우","photoUrl":"","userId":"09568145749422077039"}}},"source":["import nltk\n","nltk.download('punkt')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"EL5y_iQUjpiH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"outputId":"3d9dd063-98c2-4216-90fa-4bd267cf5b20","executionInfo":{"status":"ok","timestamp":1584600876785,"user_tz":-540,"elapsed":536,"user":{"displayName":"이진우","photoUrl":"","userId":"09568145749422077039"}}},"source":["# English corpus를 토큰화하기 위한 도구 제공하는 NLTK\n","# do | n't 로 분리\n","from nltk.tokenize import word_tokenize\n","print(word_tokenize(\"Don't be fooled by the dark sounding name, Mr.Jone's orphanage is as cheery as cheery goes for a pastry shop.\"))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["['Do', \"n't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr.Jone', \"'s\", 'orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Zg76JlxSky8h","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"outputId":"cf10a67c-7ce6-4a33-c72f-e32cf100a761","executionInfo":{"status":"ok","timestamp":1584601028141,"user_tz":-540,"elapsed":575,"user":{"displayName":"이진우","photoUrl":"","userId":"09568145749422077039"}}},"source":["from nltk.tokenize import WordPunctTokenizer\n","# wordPunctTokenizer는 구두점 별도 분류하는 특징을 가짐\n","print(WordPunctTokenizer().tokenize(\"Don't be fooled by the dark sounding name, Mr.Jone's orphanage is as cheery as cheery goes for a pastry shop.\"))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["['Don', \"'\", 't', 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr', '.', 'Jone', \"'\", 's', 'orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i1dqTTF5jsdN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"outputId":"5b07c181-3c77-4abb-bcde-7c3228002d43","executionInfo":{"status":"ok","timestamp":1584601203590,"user_tz":-540,"elapsed":556,"user":{"displayName":"이진우","photoUrl":"","userId":"09568145749422077039"}}},"source":["# 케라스의 토큰화 모듈\n","# 기본적으로 모든 알파벳의 소문자화, 구두점들을 제거하지만 don't 같은 아포스트로피는 보존\n","from tensorflow.keras.preprocessing.text import text_to_word_sequence\n","print(text_to_word_sequence(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["[\"don't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', 'mr', \"jone's\", 'orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"at_H7ubJm9un","colab_type":"text"},"source":["˙ 토큰화는 좀 더 섬세해야..</br>\n","=> 구두점이나 특수 문자를 단순 제외해서는 안 됨 </br>\n","=> 줄임말과 단어 내에 띄어쓰기가 있는 경우 ex) we're, I'm 같은 | 한 단어로 봐야죠</br>\n","\n","\n","# Penn Treebank Tokenization </br>\n","=> 표준 토큰화 방법 중 1 \n","1) - 로 구성된 단어는 하나로 유지 </br>\n","2) doesn't 와 같이 아포스트로피로 '접어'가 함께하는 단어 분리 </br>"]},{"cell_type":"code","metadata":{"id":"pQcdMe7jl4Bo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"outputId":"9176ed49-3e88-47de-ecf3-0c005e6f405b","executionInfo":{"status":"ok","timestamp":1584602901666,"user_tz":-540,"elapsed":603,"user":{"displayName":"이진우","photoUrl":"","userId":"09568145749422077039"}}},"source":["from nltk.tokenize import TreebankWordTokenizer\n","tokenizer = TreebankWordTokenizer()\n","text=\"Starting a home-based restaurant may be an ideal. it doesn't have a food chain or restaurant of their own.\"\n","print(tokenizer.tokenize(text))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["['Starting', 'a', 'home-based', 'restaurant', 'may', 'be', 'an', 'ideal.', 'it', 'does', \"n't\", 'have', 'a', 'food', 'chain', 'or', 'restaurant', 'of', 'their', 'own', '.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hWxzDOvisWlQ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}