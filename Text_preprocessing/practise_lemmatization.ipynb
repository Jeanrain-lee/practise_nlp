{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "practise_lemmatization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPXDWj6F9uR+BE0McgXMdJv"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiF3VUn6xCYs",
        "colab_type": "text"
      },
      "source": [
        "˙ 토큰화 전 텍스트를 용도에 맞게 cleaning 및 normalization을 해야함 </br>\n",
        "# cleaning \n",
        ":: 갖고 있는 코퍼스로부터 노이즈 데이터 제거\n",
        " => 불필요한 단어 제거 (등장 빈도가 적음, 영어권 언어에서 길이 짧은 단어 삭제)\n",
        "\n",
        "# normalization\n",
        ":: 표현 방법이 다른 단어들을 통합, 같은 단어로 만들기  </br>\n",
        " => 규칙 기반 표기 다름 (US / USA) </br>\n",
        " => 대, 소문자 통합 \n",
        "\n",
        "# Regular Expression (정규 표현식)\n",
        "데이터셋에서 특징을 잡아낼 수 있으면 정규 표현식을 통해 제거 가능 (ex :: 기사 포스팅 시간, HTML 태그...)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjvycSQF3ljW",
        "colab_type": "text"
      },
      "source": [
        "˙ 정규화 기법 중 데이터셋에 있는 단어의 개수를 줄일 수 있는 기법 :: 표제어 추출(lemmatization)과 어간 추출(stemming)의 개념 학습 </br>\n",
        " => 목적 :: 눈으로 봤을 때는 다르지만 단어 하나로 일반화 가능하다면 하겠다 </br>\n",
        " : 단어의 빈도수를 기반으로 문제를 푸는 (BoW :: Bag of Words)에서 주로 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw32jApT4OCB",
        "colab_type": "text"
      },
      "source": [
        "## Lemmatization :: 표제어 추출\n",
        "=> 단어로부터 표제어 찾기 (ex : am, are, is => be)\n",
        "=> 단어의 형태학적 파싱 (형태소의 두 가지 종류인 어간(stem_단어의 의미를 담은 핵심부분)과 접사(affix_ 추가적인 의미 부여) 분류 </br>\n",
        "ex) dogs => dog / s\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15rA0-xVCJKX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "72c5c37c-cb9d-4109-d92f-e079feb40c0e"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wjBIEfSwrHQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fa4e1183-f48d-4dcf-f6dd-ce52f7e4d684"
      },
      "source": [
        "# 표제어 추출은 원단어의 품사 정보를 알아야 정확한 정보 get 가능\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "n=WordNetLemmatizer()\n",
        "words=['flies', 'dies','rules', 'did', 'bubble', 'cats', 'bamboos', 'lying', 'flying', 'stones', 'stone']\n",
        "print([n.lemmatize(w) for w in words])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['fly', 'dy', 'rule', 'did', 'bubble', 'cat', 'bamboo', 'lying', 'flying', 'stone', 'stone']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYCwUJ4DCDSo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "908a1fb9-630c-45d8-cc6b-372ee4f39814"
      },
      "source": [
        "# input으로 동사 단어임을 inform\n",
        "n.lemmatize('dies', 'v')\n",
        "n.lemmatie()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'die'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    }
  ]
}